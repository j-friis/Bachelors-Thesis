{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import laplace\n",
    "import scipy.stats\n",
    "import psycopg2\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from datetime import timedelta  \n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed query and closed connection.\n",
      "Executed query and closed connection.\n"
     ]
    }
   ],
   "source": [
    "param_dic = {\n",
    "    \"host\"      : \"localhost\",\n",
    "    \"database\"  : \"bachelorBesoeg2014\",\n",
    "    \"user\"      : \"postgres\",\n",
    "    \"password\"  : \"password\",\n",
    "    \"port\"      : \"5432\"\n",
    "}\n",
    "\n",
    "def execRangeQuery(params_dic,dates):\n",
    "    query = \"\"\"\n",
    "    SELECT\n",
    "    sum(count_)\n",
    "    FROM _775147\n",
    "    WHERE\n",
    "    time_ >= '{date0}'\n",
    "    AND time_ <=  '{date1}'\n",
    "    ;\n",
    "    \"\"\".format(date0 = dates[0], date1 = dates[1])\n",
    "    try:\n",
    "        connection = psycopg2.connect(**params_dic)\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(query)\n",
    "        record = cursor.fetchall()\n",
    "        return record\n",
    "    except (Exception, psycopg2.Error) as error :\n",
    "        connection = False\n",
    "        print (\"Error while connecting to PostgreSQL\", error)\n",
    "    finally:\n",
    "        if(connection):\n",
    "            cursor.close()\n",
    "            connection.close()\n",
    "            print(\"Executed query and closed connection.\")\n",
    "\n",
    "def execQuery(params_dic,query):\n",
    "    try:\n",
    "        connection = psycopg2.connect(**params_dic)\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(query)\n",
    "        record = cursor.fetchall()\n",
    "        return record\n",
    "    except (Exception, psycopg2.Error) as error :\n",
    "        connection = False\n",
    "        print (\"Error while connecting to PostgreSQL\", error)\n",
    "    finally:\n",
    "        if(connection):\n",
    "            cursor.close()\n",
    "            connection.close()\n",
    "            print(\"Executed query and closed connection.\")\n",
    "#\"\"\"select count(*) as number_of_dates, count(DISTINCT  count_) as distinct_count from _775147;\"\"\"\n",
    "query = \"\"\"select time_ from _775147;\"\"\"\n",
    "result = execQuery(param_dic, query)\n",
    "dates = [(date[0]) for date in result]\n",
    "\n",
    "query = \"\"\"select count_ from _775147;\"\"\"\n",
    "result = execQuery(param_dic, query)\n",
    "\"\"\"\n",
    "print(result)\n",
    "print(type(result))\n",
    "print(type(result[0]))\n",
    "print((str(result[0][0])))\n",
    "\"\"\"\n",
    "counts = [(count[0]) for count in result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_missing_dates(old_dates):\n",
    "    start_date = dates[0]\n",
    "    end_date = dates[-1]\n",
    "    all_dates = pd.date_range(start = start_date, end = end_date).to_pydatetime().tolist()\n",
    "    return [(date.date()) for date in all_dates]\n",
    "    \n",
    "def add_missing_counts(old_counts, old_dates, new_dates):\n",
    "        \"\"\"Adds 0 to the list of counts where there was missing dates\n",
    "        Parameters:\n",
    "        old_counts (list of int): List counts for each day with \n",
    "        old_dates (list of datetime.date): List of dates that is not countious\n",
    "        Returns:\n",
    "        List of countious starting with the first value of \n",
    "        \"\"\"\n",
    "        zip_iterator = zip(old_dates, old_counts)\n",
    "        missing_dict =  dict(zip_iterator)\n",
    "        all_counts = np.zeros(len(new_dates))\n",
    "        for i, date in enumerate(new_dates):\n",
    "            val = missing_dict.get(date, 0)\n",
    "            all_counts[i] = val\n",
    "            \n",
    "        return all_counts\n",
    "    \n",
    "    \n",
    "all_dates = add_missing_dates(dates)\n",
    "all_counts =  add_missing_counts(counts, dates, all_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5941.15140322275\n",
      "1743.0\n",
      "[218. 207. 207. 217. 256. 242. 213. 218. 188. 198. 228. 208. 210. 210.\n",
      " 203. 225. 183. 199. 229. 235. 209. 195. 207. 184. 232. 203. 215. 208.\n",
      " 200. 210. 199. 200. 202. 211. 202. 181. 232. 204. 225. 195. 212. 227.\n",
      " 202. 194. 173. 194. 193. 194. 204. 190. 190. 206. 186. 223. 210. 218.\n",
      " 219. 214. 212. 210. 212. 231. 196. 215. 196. 211. 192. 205. 199. 189.\n",
      " 226. 214. 212. 247. 214. 207. 226. 221. 210. 203. 201. 203. 191. 205.\n",
      " 204. 200. 207. 217. 223. 209. 201. 200. 223. 192. 205. 213. 227. 232.\n",
      " 215. 186. 212. 229. 211. 221. 236. 190. 193. 200. 217. 208. 201. 197.\n",
      " 184. 200. 198. 197. 212. 229. 208. 205. 218. 192. 197. 201. 188. 228.\n",
      " 215. 207.]\n"
     ]
    }
   ],
   "source": [
    "class OLH_flat:\n",
    "    def __init__(self, epsilon, dates, counts):\n",
    "        \"\"\"Setup of the datastructere\n",
    "        Parameters:\n",
    "        T (int): The lenght of the stream\n",
    "        epsilon (float): The height of the full binary tree. \n",
    "        dates (Array): The dates of the stream\n",
    "        counts (Array): The count for each of the dates\n",
    "        Returns:\n",
    "        A epsilon differintial datastructe\n",
    "        \"\"\"\n",
    "        self.epsilon = epsilon\n",
    "        self.all_dates = dates\n",
    "        self.all_counts = counts\n",
    "        if len(dates) < (dates[-1]-dates[0]).days:\n",
    "            print('here')\n",
    "            self.all_dates = self.__add_missing_dates(dates)\n",
    "            self.all_counts = self.__add_missing_counts(counts,dates)\n",
    "            \n",
    "        #Make dict for date indexing\n",
    "        values = np.arange(0,len(self.all_dates))\n",
    "        zip_iterator = zip(self.all_dates, values)\n",
    "        self.idx_dict =  dict(zip_iterator)\n",
    "    \n",
    "        self.noise_counts = self.__process(self.all_dates, self.all_counts)\n",
    "        #Check if we are we have missing dates.\n",
    "        \n",
    "    def __add_missing_dates(self, old_dates):\n",
    "        \"\"\"Add missing dates in a list\n",
    "        Parameters:\n",
    "        old_dates (list of datetime.date): List of dates that is not countious\n",
    "        Returns:\n",
    "        List of countious starting with the first value of \n",
    "        \"\"\"\n",
    "        start_date = dates[0]\n",
    "        end_date = dates[-1]\n",
    "        all_dates = pd.date_range(start = start_date, end = end_date).to_pydatetime().tolist()\n",
    "        return [(date.date()) for date in all_dates]\n",
    "    \n",
    "    def __add_missing_counts(self, old_counts, old_dates):\n",
    "        \"\"\"Adds 0 to the list of counts where there was missing dates\n",
    "        Parameters:\n",
    "        old_counts (list of int): List counts for each day with \n",
    "        old_dates (list of datetime.date): List of dates that is not countious\n",
    "        Returns:\n",
    "        List of countious starting with the first value of \n",
    "        \"\"\"\n",
    "        zip_iterator = zip(old_dates, old_counts)\n",
    "        missing_dict =  dict(zip_iterator)\n",
    "        all_counts = np.zeros(len(self.dates))\n",
    "        for i, date in enumerate(self.dates):\n",
    "            val = missing_dict.get(date, 0)\n",
    "            all_counts[i] = val\n",
    "            \n",
    "        return all_counts\n",
    "    \n",
    "    def OLH_func(self, x, g):\n",
    "        if np.random.uniform(0,1) < np.exp(self.epsilon)/(np.exp(self.epsilon)+g-1):\n",
    "            #print('if')\n",
    "            return x\n",
    "        else:\n",
    "            return np.random.randint(low = 0, high = g)\n",
    "        \n",
    "    def OLH_answer(self, count, N, g):\n",
    "        p = np.exp(self.epsilon)/(np.exp(self.epsilon)+g-1)\n",
    "        #print(p - 1/g)\n",
    "        #print(f'p = {p}')\n",
    "        return (count- N/g) / (p)\n",
    "\n",
    "    def __process(self, dates, counts):\n",
    "        OLH_count = np.zeros(len(counts))\n",
    "        D = len(dates)\n",
    "        \n",
    "        for idx, count in enumerate(counts):\n",
    "            for i in range(0,int(count)):\n",
    "                response = self.OLH_func(idx, D)\n",
    "                OLH_count[response] = OLH_count[response] + 1\n",
    "                \n",
    "        return OLH_count\n",
    "    \n",
    "    def answer(self, dates):\n",
    "        \"\"\"Calculates the path of index in full binary string\n",
    "\n",
    "        Parameters:\n",
    "        dates (tuple of string): Two dates in the format string 2000-12-19. \n",
    "\n",
    "        Returns:\n",
    "        float: The private range count\n",
    "        \"\"\"\n",
    "        N = np.sum(self.noise_counts)\n",
    "        D = len(self.noise_counts)\n",
    "        if (len(dates) < 2):\n",
    "            #There is only one date\n",
    "            date_obj_0 = datetime.strptime(dates[0],'%Y-%m-%d').date()\n",
    "\n",
    "            idx = self.idx_dict[date_obj_0]\n",
    "            noise_count = self.noise_counts[idx]\n",
    "            return OLH_answer(noise_count, N, D)\n",
    "            \n",
    "        else:\n",
    "            date_obj_0 = datetime.strptime(dates[0],'%Y-%m-%d').date()\n",
    "            date_obj_1 = datetime.strptime(dates[1],'%Y-%m-%d').date()\n",
    "            idx_0 = self.idx_dict[date_obj_0]\n",
    "            idx_1 = self.idx_dict[date_obj_1]\n",
    "            #print(idx_0)\n",
    "            #print(idx_1)\n",
    "            #idx_0 is not 0\n",
    "            noise_sum = 0.0\n",
    "            for i in range(idx_0, idx_1+1):\n",
    "                #print(i)\n",
    "                #print(self.OLH_answer(self.noise_counts[i], N, D))\n",
    "                noise_sum = noise_sum + self.OLH_answer(self.noise_counts[i], N, D)\n",
    "            return noise_sum\n",
    "    \n",
    "    def real_answer(self, dates):\n",
    "        if len(dates) < 2:\n",
    "            date_obj_0 = datetime.strptime(dates[0],'%Y-%m-%d').date()\n",
    "            return self.all_counts[self.idx_dict[date_obj_0]]\n",
    "        else:\n",
    "            date_obj_0 = datetime.strptime(dates[0],'%Y-%m-%d').date()\n",
    "            date_obj_1 = datetime.strptime(dates[1],'%Y-%m-%d').date()\n",
    "            sum_ = np.sum(self.all_counts[self.idx_dict[date_obj_0]: self.idx_dict[date_obj_1]+1])  \n",
    "            return sum_ \n",
    "\n",
    "query_dates = ('2014-01-04','2014-01-13')\n",
    "epsilon = 0.7\n",
    "FLAT_OLH = OLH_flat(epsilon, all_dates[:128], all_counts[:128])\n",
    "print(FLAT_OLH.answer(query_dates))\n",
    "print(FLAT_OLH.real_answer(query_dates))\n",
    "print(FLAT_OLH.noise_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OUE:\n",
    "    def __init__(self, epsilon):\n",
    "        # We need the stream to be a power of 2\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "    \n",
    "    def process(self, e_i):\n",
    "        o_i = e_i.copy()\n",
    "        for idx, j in enumerate(e_i):\n",
    "            if i == 1:\n",
    "                o_i[idx] = np.random.randint(2)\n",
    "            else:\n",
    "                if np.random.uniform(0,1) < 1/(1+np.exp(epsilon)):\n",
    "                    o_i[idx] = 1\n",
    "                else:\n",
    "                    o_i[idx] = 0\n",
    "                    \n",
    "    def aggreation(self, day, lst):\n",
    "        return ( ( lst[:,day] +len(lst)/(1+np.exp(epsilon))) * (1/2 -1/(1+np.exp(epsilon))))\n",
    "        \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2005 days, 0:00:00\n"
     ]
    }
   ],
   "source": [
    "len(all_dates)\n",
    "print(all_dates[0]-all_dates[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "oue_count_lock = threading.Lock()\n",
    "oue_count_lock.acquire()\n",
    "oue_count_lock.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(oue_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OUE_func_2(e_i, epsilon):\n",
    "    #print('Call')\n",
    "    #print(e_i)\n",
    "    if e_i == 1:\n",
    "        #print('if')\n",
    "        return np.random.randint(2)\n",
    "    else:\n",
    "        #print('else')\n",
    "        if np.random.uniform(0,1) < 1/(1+np.exp(epsilon)):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OUE_answear(data, i, epsilon):\n",
    "    return (data[i]/len(data) + len(data)/(1+np.exp(epsilon))) / (1/2 -1/(1+np.exp(epsilon)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = len(all_dates) \n",
    "oue_count = np.zeros(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-b373dfa2ec1e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0msparse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0msparse\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mdense\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0moue_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moue_count\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdense\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\envs\\bachelor\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2106\u001b[0m             \u001b[0mvargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_n\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_n\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2108\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_vectorize_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2110\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_ufunc_and_otypes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\envs\\bachelor\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36m_vectorize_call\u001b[1;34m(self, func, args)\u001b[0m\n\u001b[0;32m   2190\u001b[0m                       for a in args]\n\u001b[0;32m   2191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2192\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2194\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnout\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-27-2022ad43e898>\u001b[0m in \u001b[0;36mOUE_func_2\u001b[1;34m(e_i, epsilon)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;31m#print('else')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "vfunc = np.vectorize(OUE_func_2, otypes = [int])\n",
    "epsilon = 1\n",
    "vfunc([0,1,1,1,1], epsilon)\n",
    "for idx, count in enumerate(all_counts):\n",
    "    #print(idx)\n",
    "    #print(count)\n",
    "    for i in range(0,int(count)):\n",
    "        sparse = np.zeros(D)\n",
    "        sparse[idx] = 1\n",
    "        dense = vfunc(sparse,epsilon)\n",
    "        oue_count = oue_count + dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "239.0\n",
      "221\n"
     ]
    }
   ],
   "source": [
    "print(idx)\n",
    "print(count)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[107.  56.  55. ...  51.  56.  56.]\n"
     ]
    }
   ],
   "source": [
    "print(oue_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.savetxt('oue_count.csv', oue_count, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149.37856036171803\n"
     ]
    }
   ],
   "source": [
    "print(( oue_count[0] +len(oue_count)/(1+np.exp(epsilon))) * (1/2 -1/(1+np.exp(epsilon))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vfunc = np.vectorize(OUE_func_2, otypes = [int])\n",
    "vfunc([0,1,1,1,1], 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.718281828459045"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epsilon = 1\n",
    "np.exp(epsilon)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OUE_func(e_i, epsilon):\n",
    "    o_i = e_i.copy()\n",
    "    for idx, j in enumerate(e_i):\n",
    "        if j == 1:\n",
    "            o_i[idx] = np.random.randint(2)\n",
    "        else:\n",
    "            if np.random.uniform(0,1) < 1/(1+np.exp(epsilon)):\n",
    "                o_i[idx] = 1\n",
    "            else:\n",
    "                o_i[idx] = 0\n",
    "    return o_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class flat_OUE:\n",
    "    def __init__(self, epsilon, dates, counts):\n",
    "        \n",
    "        self.dates = dates\n",
    "        self.real_counts = counts\n",
    "        self.epsilon = epsilon\n",
    "        self.counts = self.process(dates, counts)\n",
    "        self.D = len(dates)\n",
    "        \n",
    "        values = np.arange(0,len(self.dates))\n",
    "        zip_iterator = zip(self.dates, values)\n",
    "        self.idx_dict =  dict(zip_iterator)\n",
    "    \n",
    "    def process(self, dates, counts):        \n",
    "        vfunc = np.vectorize(OUE_func_2, otypes = [int])\n",
    "        for idx, count in enumerate(all_counts):\n",
    "            for i in range(0,int(count)):\n",
    "                sparse = np.zeros(D)\n",
    "                sparse[idx] = 1\n",
    "                dense = vfunc(sparse,self.epsilon)\n",
    "                oue_count = oue_count + dense\n",
    "        return oue_count\n",
    "    \n",
    "    def answer(self, dates):\n",
    "        \n",
    "        if (len(dates) < 2):\n",
    "                date_obj_0 = datetime.strptime(dates[0],'%Y-%m-%d').date()\n",
    "                #print(date_obj_0)\n",
    "                #print(type(date_obj_0))\n",
    "                idx = self.idx_dict[date_obj_0]\n",
    "                return self.noise_counts[idx]\n",
    "            \n",
    "        else:\n",
    "            date_obj_0 = datetime.strptime(dates[0],'%Y-%m-%d').date()\n",
    "            date_obj_1 = datetime.strptime(dates[1],'%Y-%m-%d').date()\n",
    "            idx_0 = self.idx_dict[date_obj_0]\n",
    "            idx_1 = self.idx_dict[date_obj_1]\n",
    "\n",
    "                #idx_0 is not 0\n",
    "            if idx_0:\n",
    "                return self.noise_counts[idx_1] - self.noise_counts[idx_0-1]            \n",
    "            else:\n",
    "                return self.noise_counts[idx_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OLH_func(x, epsilon, g):\n",
    "    if np.random.uniform(0,1) < np.exp(epsilon)/(np.exp(epsilon)+g-1):\n",
    "        #print('if')\n",
    "        return x\n",
    "    else:\n",
    "        return np.random.randint(low = 0, high = g)\n",
    "    \n",
    "def OLH_answer(data, j, epsilon, N, g):\n",
    "    p = np.exp(epsilon)/(np.exp(epsilon)+g-1)\n",
    "    #print(p - 1/g)\n",
    "    return (data[j]- N/g) / (p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0010028580256262031\n"
     ]
    }
   ],
   "source": [
    "epsilon = 0.7\n",
    "g = 2005\n",
    "print(np.exp(epsilon)/(np.exp(epsilon)+g+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = len(all_dates) \n",
    "OLH_count = np.zeros(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1\n",
    "for idx, count in enumerate(all_counts):\n",
    "    for i in range(0,int(count)):\n",
    "        response = OLH_func(idx, epsilon, D)\n",
    "        OLH_count[response] = OLH_count[response] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29277.0\n",
      "38355.93149323584\n",
      "var should be 9.151743117683762e-07\n"
     ]
    }
   ],
   "source": [
    "#print(OLH_count)\n",
    "#print(np.sum(OLH_count))\n",
    "print(all_counts[1174])\n",
    "print(OLH_answer(OLH_count, 1174, epsilon, np.sum(OLH_count), D))\n",
    "#N = np.sum(all_counts)\n",
    "N = len(all_counts)\n",
    "print(f'var should be {4*np.exp(epsilon) / (N*np.exp(epsilon) - N)**2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons = np.array([2,1.4,1.2,1,0.8,0.7,0.5,0.4,0.3])\n",
    "error_dicts = {}\n",
    "test_dates = all_dates[:32].copy()\n",
    "test_counts = all_counts[:32].copy()\n",
    "for e in epsilons:\n",
    "    print(e)\n",
    "    number_of_queries = 100\n",
    "    range_dates = ('2014-01-02','2014-01-9')\n",
    "    answears = np.zeros(number_of_queries)\n",
    "    corret_answear = np.sum(all_counts[0:8])\n",
    "    for i in range(0,number_of_queries):\n",
    "        hhs = hhs = HH_OLH(test_dates, test_counts,OLH_func,e)\n",
    "        a = hh_olh_answer(hhs, range_dates, HH_OLH_answer, test_dates, test_counts, e)\n",
    "        answears[i] = a\n",
    "    error = np.abs(corret_answear-answears)\n",
    "    max_error = np.amax(error)\n",
    "    min_error = np.amin(error)\n",
    "    true_values = np.full(number_of_queries, corret_answear)\n",
    "    #vfunc = np.vectorize(relative_error)\n",
    "    #rel_erorrs = vfunc(answears, corret_answear)\n",
    "    mse = mean_squared_error(true_values, answears)\n",
    "    error_dicts[e] = {'mse': mse, 'max': max_error, 'min': min_error, 'abs': np.mean(error)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting all error values from dict\n",
    "n = len(error_dicts)\n",
    "mse_errors = np.zeros(n)\n",
    "min_errors = np.zeros(n)\n",
    "max_errors = np.zeros(n)\n",
    "abs_errors = np.zeros(n)\n",
    "\n",
    "for num, item in enumerate(error_dicts.items()):\n",
    "    mse_errors[num] = item[1]['mse']\n",
    "    min_errors[num] = item[1]['min']\n",
    "    max_errors[num] = item[1]['max']\n",
    "    abs_errors[num] = item[1]['abs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_stack = np.vstack((min_errors,mse_errors,max_errors,abs_errors)).flatten()\n",
    "min_labels = np.full(min_errors.size, 'min errors')\n",
    "mse_labels = np.full(mse_errors.size, 'mse errors')\n",
    "max_labels = np.full(max_errors.size, 'max errors')\n",
    "abs_labels = np.full(abs_errors.size, 'abs errors')\n",
    "\n",
    "\n",
    "labels_stack = np.vstack((min_labels,mse_labels,max_labels,abs_labels)).flatten()\n",
    "epsilons_stack = np.vstack((epsilons,epsilons,epsilons,epsilons)).flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn_df = pd.DataFrame({'epsilons':epsilons_stack, 'errors':error_stack,'labels':labels_stack})\n",
    "seaborn_df.to_csv('local_hh_seaborn_plotting_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.DataFrame({'epsilons':epsilons, 'min_errors':min_errors,'max_errors':min_errors,'mse_errors':mse_errors,'abs_errors':abs_errors})\n",
    "all_data.to_csv('local_hh_plotting_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns_plot = sns.catplot(x=\"epsilons\", y=\"errors\", hue=\"labels\", data=seaborn_df)\n",
    "sns_plot.set(yscale=\"log\")\n",
    "sns_plot.savefig(\"local_hh_AllErrors.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns_plot = sns.scatterplot(data=seaborn_df.loc[seaborn_df['labels'] == 'min errors'], x ='epsilons', y ='errors')\n",
    "plt.legend(labels=['min errors'])\n",
    "sns_plot.get_figure().savefig('con_min_error.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
