{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "discrete-wesley",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from psql_functions import execQuery\n",
    "from miss_data import add_missing_dates, add_missing_counts\n",
    "from sample_range_query import load_range_queries_n_split\n",
    "\n",
    "import re\n",
    "import os\n",
    "owd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "reflected-classification",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(owd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "empirical-iceland",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def load_range_queries_n_split(file, n_structures):\n",
    "    all_queries = pd.read_csv(file, sep='\\n',header=None).to_numpy().flatten()\n",
    "    split_queries = np.array_split(all_queries, n_structures)\n",
    "    return split_queries\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "confidential-generic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed query and closed connection.\n",
      "Executed query and closed connection.\n"
     ]
    }
   ],
   "source": [
    "param_dic = {\n",
    "    \"host\"      : \"localhost\",\n",
    "    \"database\"  : \"bachelorBesoeg2014\",\n",
    "    \"user\"      : \"postgres\",\n",
    "    \"password\"  : \"password\",\n",
    "    \"port\"      : \"5432\"\n",
    "}\n",
    "\n",
    "query = \"\"\"select time_ from _775147;\"\"\"\n",
    "result = execQuery(param_dic, query)\n",
    "dates = [(date[0]) for date in result]\n",
    "\n",
    "query = \"\"\"select count_ from _775147;\"\"\"\n",
    "result = execQuery(param_dic, query)\n",
    "\n",
    "counts = [(count[0]) for count in result]\n",
    "\n",
    "all_dates = add_missing_dates(dates)\n",
    "all_counts =  add_missing_counts(counts, dates, all_dates)\n",
    "\n",
    "n_data_structures = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "continuing-valentine",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "class HH_OLH_degree:\n",
    "    def __init__(self, epsilon, degree, dates, counts):\n",
    "        \"\"\"Setup of the datastructere\n",
    "        Parameters:\n",
    "        T (int): The lenght of the stream\n",
    "        epsilon (float): The height of the full binary tree. \n",
    "        dates (Array): The dates of the stream\n",
    "        counts (Array): The count for each of the dates\n",
    "        Returns:\n",
    "        A epsilon differintial datastructe\n",
    "        \"\"\"\n",
    "        self.epsilon = epsilon\n",
    "        self.all_dates = dates\n",
    "        self.all_counts = counts\n",
    "        #Check if we are we have missing dates.\n",
    "        if len(dates) < (dates[-1]-dates[0]).days:\n",
    "            #print('here')\n",
    "            self.all_dates = self.__add_missing_dates(dates)\n",
    "            self.all_counts = self.__add_missing_counts(counts,dates)\n",
    "            \n",
    "        #Make dict for date indexing\n",
    "        values = np.arange(0,len(self.all_dates))\n",
    "        zip_iterator = zip(self.all_dates, values)\n",
    "        self.idx_dict =  dict(zip_iterator)\n",
    "     \n",
    "        self.degree = degree\n",
    "        self.h = int(np.ceil(np.log(len(self.all_dates)) / np.log(degree)))\n",
    "        self.level_prob = np.full(self.h+1,1/(self.h+1))\n",
    "    \n",
    "        self.max_val = np.max(np.fromiter(self.idx_dict.values(), dtype = int))\n",
    "        self.max_idxs = (self.get_index(self.max_val,self.h))\n",
    "        self.max_idxs.reverse()\n",
    "        \n",
    "        self.tree_levels = self.__process(self.all_dates, self.all_counts)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def __add_missing_dates(self, old_dates):\n",
    "        \"\"\"Add missing dates in a list\n",
    "        Parameters:\n",
    "        old_dates (list of datetime.date): List of dates that is not countious\n",
    "        Returns:\n",
    "        List of countious starting with the first value of \n",
    "        \"\"\"\n",
    "        start_date = old_dates[0]\n",
    "        end_date = old_dates[-1]\n",
    "        all_dates = pd.date_range(start = start_date, end = end_date).to_pydatetime().tolist()\n",
    "        return [(date.date()) for date in all_dates]\n",
    "    \n",
    "    def __add_missing_counts(self, old_counts, old_dates):\n",
    "        \"\"\"Adds 0 to the list of counts where there was missing dates\n",
    "        Parameters:\n",
    "        old_counts (list of int): List counts for each day with \n",
    "        old_dates (list of datetime.date): List of dates that is not countious\n",
    "        Returns:\n",
    "        List of countious starting with the first value of \n",
    "        \"\"\"\n",
    "        zip_iterator = zip(old_dates, old_counts)\n",
    "        missing_dict =  dict(zip_iterator)\n",
    "        all_counts = np.zeros(len(self.dates))\n",
    "        for i, date in enumerate(self.dates):\n",
    "            val = missing_dict.get(date, 0)\n",
    "            all_counts[i] = val\n",
    "            \n",
    "        return all_counts\n",
    "    \n",
    "    def __process(self, dates, counts):\n",
    "        tree_levels = []\n",
    "        for i in np.arange(0,self.h+1):\n",
    "            level = np.zeros(int(self.degree**np.ceil(i)))\n",
    "            tree_levels.append(level)\n",
    "        \n",
    "        for index, (date, day_count) in enumerate(zip(dates, counts)):\n",
    "            idxs = self.get_index(index,self.h)\n",
    "            idxs.reverse()\n",
    "            #print(self.max_idxs)\n",
    "            for person in range(int(day_count)):\n",
    "                level = np.random.choice(np.arange(0, self.h+1), p = self.level_prob ) \n",
    "        \n",
    "                if level != 0:\n",
    "                    \"\"\"\n",
    "                    print(f' We are at level {level}')\n",
    "                    print(f' max index at level is {self.max_idxs[level]}')\n",
    "                    print(f'Now we hash down to {(self.degree**level)}')\n",
    "                    \"\"\"\n",
    "                    hash_value = self.max_idxs[level]\n",
    "                    response = self.OLH_func(idxs[level], hash_value)\n",
    "                    \n",
    "                else:\n",
    "                    response = 0\n",
    "                tree_levels[level][response] = tree_levels[level][response] + 1\n",
    "\n",
    "        return tree_levels\n",
    "\n",
    "    def get_index(self, date_idx, n_layers):\n",
    "        \"\"\"Calculates the path of index in full binary string\n",
    "\n",
    "        Parameters:\n",
    "        date_idx (int): The node in the bouttom layer we want to calculate a path to. \n",
    "        The bottom layer has index from 0 to 2**h-1\n",
    "        n_layers (int): The height of the full binary tree. \n",
    "\n",
    "        Returns:\n",
    "        list: of index in the path from the starting from the bottom and going up\n",
    "\n",
    "        \"\"\"\n",
    "        idx = []\n",
    "        for i in np.arange(0,n_layers):\n",
    "            if i == 0:\n",
    "                idx.append(int(date_idx))\n",
    "            else:\n",
    "                idx.append(int(idx[i-1]//self.degree))\n",
    "        idx.append(0)\n",
    "        return idx\n",
    "    \n",
    "    def get_group(self, idx, level):\n",
    "        \"\"\"Calculates the path of index in full binary string\n",
    "\n",
    "        Parameters:\n",
    "        date_idx (int): The node in the bouttom layer we want to calculate a path to. \n",
    "        The bottom layer has index from 0 to 2**h-1\n",
    "        n_layers (int): The height of the full binary tree. 0 index\n",
    "\n",
    "        Returns:\n",
    "        list: of index in the path from the starting from the bottom and going up\n",
    "\n",
    "        \"\"\"\n",
    "        if level == 0:\n",
    "            return id\n",
    "        elif idx == 0:\n",
    "            return np.arange(0,self.degree)\n",
    "        else:\n",
    "            group_index = idx //self.degree\n",
    "            level_indicis = np.arange(0,self.degree**level)\n",
    "\n",
    "            split_ratio = (len(level_indicis) // self.degree)\n",
    "            level_indicis_split = np.array_split(level_indicis, split_ratio)\n",
    "            \n",
    "            return level_indicis_split[group_index]\n",
    "    \n",
    "    def OLH_func(self, x, g):\n",
    "        if np.random.uniform(0,1) < np.exp(self.epsilon)/(np.exp(self.epsilon)+g-1):\n",
    "            return x\n",
    "        else:\n",
    "            return np.random.randint(low = 0, high = g)\n",
    "    \n",
    "    def OLH_aggre(self, count, N, g):\n",
    "        p = np.exp(self.epsilon)/(np.exp(self.epsilon)+g-1)\n",
    "        #print(p - 1/g)\n",
    "        #print(f'p = {p}')\n",
    "        return (count - (1-p)*N/g) / (p)\n",
    "    \n",
    "    def turns_right(self, path):\n",
    "        #0 is left 1 is right\n",
    "        direction_lst = []\n",
    "        for i in range(len(path)-1):\n",
    "            current = path[i]\n",
    "            nxt = path[i+1]\n",
    "            if nxt == 0:\n",
    "                #We went left\n",
    "                direction_lst.append(0)\n",
    "            elif current == 0 and current < nxt:\n",
    "                #We went right\n",
    "                direction_lst.append(1)\n",
    "            elif self.degree * current < nxt:\n",
    "                #We went right\n",
    "                direction_lst.append(1)\n",
    "            else:\n",
    "                #print('else')            \n",
    "                direction_lst.append(0)\n",
    "\n",
    "        return direction_lst\n",
    "\n",
    "    def turns_left(self, path):\n",
    "        #0 is left 1 is right\n",
    "        direction_lst = []\n",
    "        for i in range(len(path)-1):\n",
    "            current = path[i]\n",
    "            nxt = path[i+1]\n",
    "            #Checks\n",
    "            if nxt == 0:\n",
    "                #We went left\n",
    "                direction_lst.append(0)\n",
    "            #Checks\n",
    "            elif nxt == current*self.degree + self.degree - 1:\n",
    "                #We went right\n",
    "                direction_lst.append(1)\n",
    "            elif current == 0 and current < nxt:\n",
    "                #We went left\n",
    "                direction_lst.append(0)\n",
    "            else:\n",
    "                direction_lst.append(0)\n",
    "\n",
    "        return direction_lst\n",
    "    \n",
    "    def answer(self, dates):\n",
    "        \"\"\"Calculates the path of index in full binary string\n",
    "\n",
    "        Parameters:\n",
    "        dates (tuple of string): Two dates in the format string 2000-12-19. \n",
    "\n",
    "        Returns:\n",
    "        float: The private range count\n",
    "        \"\"\"\n",
    "            \n",
    "        date_obj_0 = datetime.strptime(dates[0],'%Y-%m-%d').date()\n",
    "        date_obj_1 = datetime.strptime(dates[1],'%Y-%m-%d').date()\n",
    "\n",
    "\n",
    "        idx_0 = self.idx_dict[date_obj_0]\n",
    "        idx_1 = self.idx_dict[date_obj_1]\n",
    "        \n",
    "        #print(idx_0)\n",
    "        #print(idx_1)\n",
    "        idx_left = idx_0-1\n",
    "        idx_right = idx_1+1\n",
    "        \n",
    "        path_to_left = np.flip(np.array(self.get_index(idx_left,self.h)))\n",
    "        path_to_right = np.flip(np.array(self.get_index(idx_right,self.h)))\n",
    "        \n",
    "        left_or_right_list_leftside = self.turns_left(path_to_left)\n",
    "        left_or_right_list_rightside = self.turns_right(path_to_right)\n",
    "        \n",
    "        range_count = 0.0\n",
    "        \n",
    "        #Starting in 0\n",
    "        if idx_0 == 0:\n",
    "            level_offset = 1\n",
    "\n",
    "            for i in range(len(left_or_right_list_rightside)):\n",
    "                if left_or_right_list_rightside[i] == 1:\n",
    "                    group = self.get_group(path_to_right[i+level_offset], i+level_offset)\n",
    "                    idx_sss = np.where(group == path_to_right[i+level_offset])[0][0]\n",
    "\n",
    "                    count_nodes = self.tree_levels[i+level_offset][group[:idx_sss]]\n",
    "                    hash_value = self.max_idxs[i+level_offset]\n",
    "                    \n",
    "                    for node in count_nodes:\n",
    "                        range_count = range_count + self.OLH_aggre(node, np.sum(self.tree_levels[i+level_offset]), hash_value)\n",
    "    \n",
    "        elif idx_1 == np.max(np.fromiter(self.idx_dict.values(), dtype = int)):\n",
    "            \n",
    "            level_offset = 1\n",
    "\n",
    "            for i in range(len(left_or_right_list_leftside)):\n",
    "                if left_or_right_list_leftside[i] == 0:\n",
    "\n",
    "                    group = self.get_group(path_to_left[i+level_offset], i+level_offset)\n",
    "                    idx_sss = np.where(group == path_to_left[i+level_offset])[0][0]\n",
    "\n",
    "                    count_nodes = self.tree_levels[i+level_offset][group[idx_sss+1:]]\n",
    "                    \n",
    "                    hash_value = self.max_idxs[i+level_offset]\n",
    "                    for node in count_nodes:\n",
    "                        #print(node)\n",
    "                        \n",
    "                        range_count = range_count + self.OLH_aggre(node, np.sum(self.tree_levels[i+level_offset]), hash_value)\n",
    "                    \n",
    "                    \n",
    "        else:\n",
    "            level_offset = 1\n",
    "            left_count = []\n",
    "            left_count_group = []\n",
    "\n",
    "            for i in range(len(left_or_right_list_rightside)):\n",
    "                if left_or_right_list_rightside[i] == 1:\n",
    "                    group = self.get_group(path_to_right[i+level_offset], i+level_offset)\n",
    "                    idx_sss = np.where(group == path_to_right[i+level_offset])[0][0]\n",
    "\n",
    "                    left_count_group.append(group[:idx_sss]) \n",
    "\n",
    "                    count_nodes = self.tree_levels[i+level_offset][group[:idx_sss]]\n",
    "                    left_count.append(count_nodes)\n",
    "\n",
    "                else:\n",
    "                    left_count_group.append(np.array([]))\n",
    "                    left_count.append(np.array([]))\n",
    "\n",
    "            #The search right side\n",
    "            right_count = []\n",
    "            right_count_group = []\n",
    "\n",
    "            for i in range(len(left_or_right_list_leftside)):\n",
    "                if left_or_right_list_leftside[i] == 0:\n",
    "\n",
    "                    group = self.get_group(path_to_left[i+level_offset], i+level_offset)\n",
    "                    idx_sss = np.where(group == path_to_left[i+level_offset])[0][0]\n",
    "\n",
    "                    right_count_group.append(group[idx_sss+1:]) \n",
    "\n",
    "                    count_nodes = self.tree_levels[i+level_offset][group[idx_sss+1:]]\n",
    "                    right_count.append(count_nodes)\n",
    "\n",
    "                else:\n",
    "                    right_count_group.append(np.array([]))\n",
    "                    right_count.append(np.array([]))\n",
    "\n",
    "            for i in range(len(left_count_group)):\n",
    "                \n",
    "                hash_value = self.max_idxs[i + level_offset]\n",
    "                if left_count_group[i].size != 0 and right_count_group[i].size != 0:\n",
    "                    #Both not zero\n",
    "                    group_left = self.get_group(left_count_group[i][0], i+ level_offset)\n",
    "                    group_right = self.get_group(right_count_group[i][0], i+ level_offset)\n",
    "\n",
    "                    if not (np.array_equal(group_left,group_right)):\n",
    "                        for node in left_count_group[i]:\n",
    "                            range_count = range_count + self.OLH_aggre(node, np.sum(self.tree_levels[i+level_offset]), hash_value)\n",
    "                        for node in right_count_group[i]:\n",
    "                            range_count = range_count + self.OLH_aggre(node, np.sum(self.tree_levels[i+level_offset]), hash_value)\n",
    "                    else:\n",
    "                        count_nodes = np.intersect1d(left_count_group[i], right_count_group[i])\n",
    "                        for node in count_nodes:\n",
    "                            range_count = range_count + self.OLH_aggre(node, np.sum(self.tree_levels[i+level_offset]), hash_value)\n",
    "\n",
    "                if left_count_group[i].size != 0 and right_count_group[i].size == 0:\n",
    "                    #Left not zero\n",
    "                    for node in left_count_group[i]:\n",
    "                        range_count = range_count + self.OLH_aggre(node, np.sum(self.tree_levels[i+level_offset]), hash_value)\n",
    "\n",
    "                if right_count_group[i].size != 0 and left_count_group[i].size == 0:\n",
    "                    #Right not zero\n",
    "                    for node in right_count_group[i]:\n",
    "\n",
    "                        range_count = range_count + self.OLH_aggre(node, np.sum(self.tree_levels[i+level_offset]), hash_value)\n",
    "        #Correct for sampling differnt levels in the tree               \n",
    "        return range_count * (self.h+1)\n",
    "    \n",
    "    def real_answer(self, dates):\n",
    "        if len(dates) < 2:\n",
    "            date_obj_0 = datetime.strptime(dates[0],'%Y-%m-%d').date()\n",
    "            return self.all_counts[self.idx_dict[date_obj_0]]\n",
    "        else:\n",
    "            date_obj_0 = datetime.strptime(dates[0],'%Y-%m-%d').date()\n",
    "            date_obj_1 = datetime.strptime(dates[1],'%Y-%m-%d').date()\n",
    "            sum_ = np.sum(self.all_counts[self.idx_dict[date_obj_0]: self.idx_dict[date_obj_1]+1])  \n",
    "            return sum_ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "integral-hands",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()\n",
    "os.chdir(os.getcwd()+'/'+'range_queries/flat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "prerequisite-preliminary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['flat_N=1024_r=44.csv',\n",
       " 'flat_N=128_r=9.csv',\n",
       " 'flat_N=2048_r=64.csv',\n",
       " 'flat_N=256_r=24.csv',\n",
       " 'flat_N=32_r=6.csv',\n",
       " 'flat_N=512_r=35.csv',\n",
       " 'range_queries_flat_N=1024_r=44.csv',\n",
       " 'range_queries_flat_N=128_r=9.csv',\n",
       " 'range_queries_flat_N=2048_r=64.csv',\n",
       " 'range_queries_flat_N=256_r=24.csv',\n",
       " 'range_queries_flat_N=32_r=6.csv',\n",
       " 'range_queries_flat_N=512_r=35.csv']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = [f for f in os.listdir('.') if re.match(r'.*\\.csv', f)]\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "academic-chaos",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_32_flat = []\n",
    "n_128_flat = []\n",
    "n_256_flat = []\n",
    "n_512_flat = []\n",
    "n_1024_flat = []\n",
    "n_2048_flat = []\n",
    "\n",
    "for f in files:\n",
    "    if 'N=32' in f:\n",
    "        n_32_flat.append(load_range_queries_n_split(f, n_data_structures))\n",
    "    if 'N=128' in f:\n",
    "        n_128_flat.append(load_range_queries_n_split(f, n_data_structures))\n",
    "    if 'N=256' in f:\n",
    "        n_256_flat.append(load_range_queries_n_split(f, n_data_structures))\n",
    "    if 'N=512' in f:\n",
    "        n_512_flat.append(load_range_queries_n_split(f, n_data_structures))\n",
    "    if 'N=1024' in f:\n",
    "        n_1024_flat.append(load_range_queries_n_split(f, n_data_structures))\n",
    "    if 'N=2048' in f:\n",
    "        n_2048_flat.append(load_range_queries_n_split(f, n_data_structures))\n",
    "\n",
    "n_32_flat = [item for sublist in n_32_flat for item in sublist]\n",
    "n_128_flat = [item for sublist in n_128_flat for item in sublist]\n",
    "n_256_flat = [item for sublist in n_256_flat for item in sublist]\n",
    "n_512_flat = [item for sublist in n_512_flat for item in sublist]\n",
    "n_1024_flat = [item for sublist in n_1024_flat for item in sublist]\n",
    "n_2048_flat = [item for sublist in n_2048_flat for item in sublist]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "structured-audit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hh_N=1024_B=2_r=402.csv',\n",
       " 'hh_N=1024_B=3_r=296.csv',\n",
       " 'hh_N=1024_B=4_r=202.csv',\n",
       " 'hh_N=2048_B=2_r=485.csv',\n",
       " 'hh_N=2048_B=3_r=294.csv',\n",
       " 'hh_N=2048_B=4_r=288.csv',\n",
       " 'hh_N=256_B=2_r=44.csv',\n",
       " 'hh_N=256_B=3_r=217.csv',\n",
       " 'hh_N=256_B=4_r=130.csv',\n",
       " 'hh_N=512_B=2_r=325.csv',\n",
       " 'hh_N=512_B=3_r=217.csv',\n",
       " 'hh_N=512_B=4_r=200.csv']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(owd)\n",
    "os.getcwd()\n",
    "os.chdir(os.getcwd()+'/'+'range_queries/local_hh')\n",
    "os.getcwd()\n",
    "files = [f for f in os.listdir('.') if re.match(r'.*\\.csv', f)]\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increasing-narrow",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "accredited-sussex",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_256_hh = []\n",
    "n_512_hh = []\n",
    "n_1024_hh = []\n",
    "n_2048_hh = []\n",
    "\n",
    "for f in files:\n",
    "    if 'N=256' in f:\n",
    "        n_256_hh.append(load_range_queries_n_split(f, n_data_structures))\n",
    "    if 'N=512' in f:\n",
    "        n_512_hh.append(load_range_queries_n_split(f, n_data_structures))\n",
    "    if 'N=1024' in f:\n",
    "        n_1024_hh.append(load_range_queries_n_split(f, n_data_structures))\n",
    "    if 'N=2048' in f:\n",
    "        n_2048_hh.append(load_range_queries_n_split(f, n_data_structures))\n",
    "\n",
    "n_256_hh = [item for sublist in n_256_hh for item in sublist]\n",
    "n_512_hh = [item for sublist in n_512_hh for item in sublist]\n",
    "n_1024_hh = [item for sublist in n_1024_hh for item in sublist]\n",
    "n_2048_hh = [item for sublist in n_2048_hh for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "touched-macintosh",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(n_256_hh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cardiac-delay",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_answers(model, query):\n",
    "    estimation = model.answer(query)\n",
    "    correct = model.real_answer(query)  \n",
    "    return estimation, correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "baking-office",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nn_32_flat = []\\nn_128_flat = []\\nn_256_flat = []\\nn_512_flat = []\\nn_1024_flat = []\\nn_2048_flat = []\\n\\nn_256_hh = []\\nn_512_hh = []\\nn_1024_hh = []\\nn_2048_hh = []\\n\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epsilons = np.array([2,1.4,1.2,1,0.8,0.6,0.5,0.3])\n",
    "n = np.array([32,128,256,512,1024,2048])\n",
    "degrees = np.array([2,3,4])\n",
    "\n",
    "os.chdir(owd)\n",
    "#We have 50 datastruces\n",
    "\n",
    "for e in epsilons:\n",
    "    for N in n:\n",
    "        for degree in degrees:\n",
    "            csv_name_est_flat = 'results/sample_querys/local_hh/' + f'est_flat_queries_e={e}_N={N}_B={degree}.csv'\n",
    "            csv_name_cor_flat = 'results/sample_querys/local_hh/' + f'cor_flat_queries_e={e}_N={N}_B={degree}.csv'\n",
    "\n",
    "            csv_name_est_hh = 'results/sample_querys/local_hh/' + f'est_hh_queries_e={e}_N={N}_B={degree}.csv'\n",
    "            csv_name_cor_hh = 'results/sample_querys/local_hh/' + f'cor_hh_queries_e={e}_N={N}_B={degree}.csv'\n",
    "\n",
    "            answers_flat = []\n",
    "            correct_answers_flat = []\n",
    "\n",
    "            answers_hh = []\n",
    "            correct_answers_hh = []\n",
    "\n",
    "            for i in range(0,n_data_structures):\n",
    "                \"\"\"\n",
    "                degree = 4\n",
    "                local_HH = HH_OLH_degree(epsilon, degree, all_dates[:], all_counts[:])\n",
    "                \"\"\"\n",
    "                FLAT_OLH = HH_OLH_degree(e,degree, all_dates[:N], all_counts[:N])\n",
    "\n",
    "                if N == 32:\n",
    "                    for query in n_32_flat[i]:\n",
    "                        dates_split = query.split(', ')\n",
    "                        res = tuple(dates_split)\n",
    "\n",
    "                        est, cor = model_answers(FLAT_OLH, res)\n",
    "                        answers_flat.append(est)\n",
    "                        correct_answers_flat.append(cor)\n",
    "\n",
    "                if N == 128:\n",
    "                    for query in n_128_flat[i]:\n",
    "\n",
    "                        dates_split = query.split(', ')\n",
    "                        res = tuple(dates_split)\n",
    "\n",
    "                        est, cor = model_answers(FLAT_OLH, res)\n",
    "                        answers_flat.append(est)\n",
    "                        correct_answers_flat.append(cor)\n",
    "\n",
    "\n",
    "                if N == 256:\n",
    "                    for query in n_32_flat[i]:\n",
    "                        dates_split = query.split(', ')\n",
    "                        res = tuple(dates_split)\n",
    "                        est, cor = model_answers(FLAT_OLH, res)\n",
    "                        answers_flat.append(est)\n",
    "                        correct_answers_flat.append(cor)             \n",
    "\n",
    "                if N == 512:\n",
    "                    for query in n_512_flat[i]:\n",
    "                        dates_split = query.split(', ')\n",
    "                        res = tuple(dates_split)\n",
    "\n",
    "                        est, cor = model_answers(FLAT_OLH, res)\n",
    "                        answers_flat.append(est)\n",
    "                        correct_answers_flat.append(cor)\n",
    "\n",
    "                    for query in n_512_hh[i]:\n",
    "                        dates_split = query.split(', ')\n",
    "                        res = tuple(dates_split)\n",
    "\n",
    "                        est, cor = model_answers(FLAT_OLH, res)\n",
    "                        answers_hh.append(est)\n",
    "                        correct_answers_hh.append(cor)\n",
    "\n",
    "                if N == 1024:\n",
    "                    for query in n_1024_flat[i]:\n",
    "                        dates_split = query.split(', ')\n",
    "                        res = tuple(dates_split)\n",
    "\n",
    "                        est, cor = model_answers(FLAT_OLH, res)\n",
    "                        answers_flat.append(est)\n",
    "                        correct_answers_flat.append(cor)\n",
    "\n",
    "                    for query in n_1024_hh[i]:\n",
    "                        dates_split = query.split(', ')\n",
    "                        res = tuple(dates_split)\n",
    "                        est, cor = model_answers(FLAT_OLH, res)\n",
    "                        answers_hh.append(est)\n",
    "                        correct_answers_hh.append(cor)\n",
    "\n",
    "                if N == 2048:\n",
    "                    for query in n_2048_flat[i]:\n",
    "                        dates_split = query.split(', ')\n",
    "                        res = tuple(dates_split)\n",
    "\n",
    "                        est, cor = model_answers(FLAT_OLH, res)\n",
    "                        answers_flat.append(est)\n",
    "                        correct_answers_flat.append(cor)\n",
    "\n",
    "                    for query in n_2048_hh[i]:\n",
    "                        dates_split = query.split(', ')\n",
    "                        res = tuple(dates_split)\n",
    "\n",
    "                        est, cor = model_answers(FLAT_OLH, res)\n",
    "                        answers_hh.append(est)\n",
    "                        correct_answers_hh.append(cor)\n",
    "\n",
    "\n",
    "                        \n",
    "            np.savetxt(csv_name_est_flat, answers_flat, delimiter=',')\n",
    "            np.savetxt(csv_name_cor_flat, correct_answers_flat, delimiter=',')\n",
    "\n",
    "            np.savetxt(csv_name_est_hh, answers_hh, delimiter=',')\n",
    "            np.savetxt(csv_name_cor_hh, correct_answers_hh, delimiter=',')\n",
    "\n",
    "\"\"\"\n",
    "n_32_flat = []\n",
    "n_128_flat = []\n",
    "n_256_flat = []\n",
    "n_512_flat = []\n",
    "n_1024_flat = []\n",
    "n_2048_flat = []\n",
    "\n",
    "n_256_hh = []\n",
    "n_512_hh = []\n",
    "n_1024_hh = []\n",
    "n_2048_hh = []\n",
    "\n",
    "\"\"\"\n",
    "            \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "played-capability",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exact-california",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lovely-proof",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "FLAT_OLH = OLH_flat(epsilon, all_dates[:32], all_counts[:32])\n",
    "print(FLAT_OLH.answer(query_dates))\n",
    "print(FLAT_OLH.real_answer(query_dates))\n",
    "print(FLAT_OLH.noise_counts)\n",
    "print(FLAT_OLH.var)\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
