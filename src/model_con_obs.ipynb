{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import laplace\n",
    "import scipy.stats\n",
    "import psycopg2\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from psql_functions import execQuery, execRangeQuery\n",
    "from miss_data import add_missing_dates, add_missing_counts\n",
    "from sample_range_query import load_range_queries_n_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed query and closed connection.\n",
      "Executed query and closed connection.\n"
     ]
    }
   ],
   "source": [
    "param_dic = {\n",
    "    \"host\"      : \"localhost\",\n",
    "    \"database\"  : \"bachelorBesoeg2014\",\n",
    "    \"user\"      : \"postgres\",\n",
    "    \"password\"  : \"password\",\n",
    "    \"port\"      : \"5432\"\n",
    "}\n",
    "\n",
    "query = \"\"\"select time_ from _775147;\"\"\"\n",
    "result = execQuery(param_dic, query)\n",
    "dates = [(date[0]) for date in result]\n",
    "\n",
    "query = \"\"\"select count_ from _775147;\"\"\"\n",
    "result = execQuery(param_dic, query)\n",
    "\n",
    "counts = [(count[0]) for count in result]\n",
    "\n",
    "all_dates = add_missing_dates(dates)\n",
    "all_counts =  add_missing_counts(counts, dates, all_dates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There should be datapoints 2005\n",
      "There is 1794 datapoints\n",
      "So we are missing 211 datapoints\n"
     ]
    }
   ],
   "source": [
    "print(f'There should be datapoints {(dates[-1]-dates[0]).days}')\n",
    "print(f'There is {len(dates)} datapoints')\n",
    "print(f'So we are missing {(dates[-1]-dates[0]).days - len(dates)} datapoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (2048,) (1794,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-286-2d5a6816f62a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    402\u001b[0m \u001b[0mT\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.7\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 404\u001b[1;33m \u001b[0mc_o\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcen_hh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_dates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_counts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    405\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m \u001b[0mquery_dates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'2014-01-08'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'2014-01-09'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-286-2d5a6816f62a>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, epsilon, dates, counts, degree)\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlaplaces\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_laplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistogram\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_histogram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_levels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__process\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall_counts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minit_laplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-286-2d5a6816f62a>\u001b[0m in \u001b[0;36m__process\u001b[1;34m(self, counts)\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[0mhh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlaplaces\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m             \u001b[0mlevel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlaplaces\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m             \u001b[0mhh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhh\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (2048,) (1794,) "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import laplace\n",
    "from datetime import datetime\n",
    "\n",
    "class cen_hh:\n",
    "    \n",
    "    def __init__(self, epsilon, dates, counts, degree):\n",
    "        \"\"\"Setup of the datastructere\n",
    "\n",
    "        Parameters:\n",
    "        T (int): The lenght of the stream\n",
    "        epsilon (float): The height of the full binary tree. \n",
    "        dates (Array): The dates of the stream\n",
    "        counts (Array): The count for each of the dates\n",
    "        Returns:\n",
    "        A epsilon differintial datastructe\n",
    "        \"\"\"\n",
    "        \n",
    "        self.degree = degree\n",
    "        \n",
    "        self.all_dates = dates\n",
    "        self.all_counts = counts\n",
    "        #Check if we are we have missing dates.\n",
    "        if len(dates) < (dates[-1]-dates[0]).days:  \n",
    "            self.all_dates = self.__add_missing_dates(all_dates)\n",
    "            self.all_counts = self.__add_missing_counts(all_counts,dates)\n",
    "        \n",
    "        self.all_dates = self.pad_dates(self.all_dates)\n",
    "        self.all_counts = self.pad_counts(self.all_counts)\n",
    "        \n",
    "        #Make dict for date indexing\n",
    "        values = np.arange(0,len(self.all_dates))\n",
    "        zip_iterator = zip(self.all_dates, values)\n",
    "        self.idx_dict =  dict(zip_iterator)\n",
    "        \n",
    "        # We need the stream to be a power of the degree\n",
    "        self.T = int(np.ceil(np.log(len(self.all_counts)) / np.log(self.degree))+1)\n",
    "        self.epsilon = epsilon\n",
    "        self.zeta = (np.log2(self.T))/epsilon\n",
    "            \n",
    "        # The height of the \"adic tree\"\n",
    "        self.n_layers = int(np.log(self.T)/np.log(self.degree))\n",
    "        \n",
    "        # Get laplace for each node\n",
    "        self.laplaces = self.init_laplace()\n",
    "        self.histogram = self.build_histogram()\n",
    "        self.tree_levels = self.__process(self.all_counts)\n",
    "    \n",
    "    def init_laplace(self):\n",
    "        \"\"\"\n",
    "        returns: list of arrays with the correct size of laplaces variabels.\n",
    "        \"\"\"\n",
    "        laplaces = []\n",
    "        for i in np.arange(0,self.T):\n",
    "            rvs = laplace(scale=self.zeta).rvs(int(self.degree**np.ceil(i)))\n",
    "            laplaces.append(rvs)\n",
    "        \n",
    "        return laplaces\n",
    "    \n",
    "    def build_histogram(self):\n",
    "        #print(counts)\n",
    "        #print(get_group(counts,degree))\n",
    "        tree = []\n",
    "        left = counts\n",
    "        for level in range(0, int(np.ceil(np.log(len(self.all_dates)) / np.log(self.degree)))):\n",
    "            split_ratio = self.degree**level\n",
    "            left = np.array_split(counts, split_ratio)\n",
    "\n",
    "            sums = [np.sum(a) for a in left]\n",
    "            tree.append(sums)\n",
    "                     \n",
    "        tree.append(counts)\n",
    "        return tree   \n",
    "        \n",
    "    def __add_missing_dates(self, old_dates):\n",
    "        \"\"\"Add missing dates in a list\n",
    "        Parameters:\n",
    "        old_dates (list of datetime.date): List of dates that is not countious\n",
    "        Returns:\n",
    "        List of countious starting with the first value of \n",
    "        \"\"\"\n",
    "        start_date = old_dates[0]\n",
    "        end_date = old_dates[-1]\n",
    "        all_dates = pd.date_range(start = start_date, end = end_date).to_pydatetime().tolist()\n",
    "        return [(date.date()) for date in all_dates]\n",
    "    \n",
    "    def __add_missing_counts(self, old_counts, old_dates):\n",
    "        \"\"\"Adds 0 to the list of counts where there was missing dates\n",
    "        Parameters:\n",
    "        old_counts (list of int): List counts for each day with \n",
    "        old_dates (list of datetime.date): List of dates that is not countious\n",
    "        Returns:\n",
    "        List of countious starting with the first value of \n",
    "        \"\"\"\n",
    "        zip_iterator = zip(old_dates, old_counts)\n",
    "        missing_dict =  dict(zip_iterator)\n",
    "        all_counts = np.zeros(len(self.all_dates))\n",
    "        for i, date in enumerate(self.all_dates):\n",
    "            val = missing_dict.get(date, 0)\n",
    "            all_counts[i] = val\n",
    "            \n",
    "        return all_counts\n",
    "    \n",
    "    def pad_counts(self, counts):\n",
    "        levels = int(np.ceil(np.log(len(counts)) / np.log(self.degree)))\n",
    "\n",
    "        n_missing_counts =  self.degree**levels -len(counts)\n",
    "\n",
    "        missing = np.zeros(n_missing_counts, dtype=int)\n",
    "        new_counts = np.concatenate((counts,missing))\n",
    "        return new_counts\n",
    "\n",
    "    def pad_dates(self, dates):\n",
    "        levels = int(np.ceil(np.log(len(dates)) / np.log(self.degree)))\n",
    "        n_missing_dates =  self.degree**levels - len(dates)\n",
    "\n",
    "        start_date = datetime.strptime(str(dates[-1]),'%Y-%m-%d').date()\n",
    "        result = pd.date_range(start = start_date, periods = n_missing_dates).to_pydatetime().tolist()\n",
    "\n",
    "        new_dates = np.concatenate((dates,result))\n",
    "        return new_dates\n",
    "    \n",
    "    def __process(self, counts):\n",
    "        hh = []\n",
    "        for i in range(0,len(self.laplaces)):\n",
    "            level = self.laplaces[i] + self.histogram[i]\n",
    "            hh.append(level)\n",
    "        return hh  \n",
    "    \n",
    "    def get_index(self, date_idx, n_layers):\n",
    "        \"\"\"Calculates the path of index in full binary string\n",
    "\n",
    "        Parameters:\n",
    "        date_idx (int): The node in the bouttom layer we want to calculate a path to. \n",
    "        The bottom layer has index from 0 to 2**h-1\n",
    "        n_layers (int): The height of the full binary tree. \n",
    "\n",
    "        Returns:\n",
    "        list: of index in the path from the starting from the bottom and going up\n",
    "        \"\"\"\n",
    "        idx = []\n",
    "        for i in np.arange(0,n_layers):\n",
    "            if i == 0:\n",
    "                idx.append(int(date_idx))\n",
    "            else:\n",
    "                idx.append(int(idx[i-1]//2))\n",
    "        idx.append(0)\n",
    "        return idx\n",
    "    \n",
    "    def get_group(self, idx, level):\n",
    "        \"\"\"Calculates the path of index in full binary string\n",
    "\n",
    "        Parameters:\n",
    "        date_idx (int): The node in the bouttom layer we want to calculate a path to. \n",
    "        The bottom layer has index from 0 to 2**h-1\n",
    "        n_layers (int): The height of the full binary tree. 0 index\n",
    "\n",
    "        Returns:\n",
    "        list: of index in the path from the starting from the bottom and going up\n",
    "\n",
    "        \"\"\"\n",
    "        if level == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            group_index = idx //self.degree\n",
    "            level_indicis = np.arange(0,self.degree**level)\n",
    "\n",
    "            split_ratio = (len(level_indicis) // self.degree)\n",
    "            level_indicis_split = np.array_split(level_indicis, split_ratio)\n",
    "\n",
    "            return level_indicis_split[group_index]\n",
    "    \n",
    "    def turns_right(self, path):\n",
    "        #0 is left 1 is right\n",
    "        direction_lst = []\n",
    "        for i in range(len(path)-1):\n",
    "            current = path[i]\n",
    "            nxt = path[i+1]\n",
    "            if nxt == 0:\n",
    "                #We went left\n",
    "                direction_lst.append(0)\n",
    "            elif current == 0 and current < nxt:\n",
    "                #We went right\n",
    "                direction_lst.append(1)\n",
    "            elif self.degree * current < nxt:\n",
    "                #We went right\n",
    "                direction_lst.append(1)\n",
    "            else:\n",
    "                #print('else')            \n",
    "                direction_lst.append(0)\n",
    "\n",
    "        return direction_lst\n",
    "\n",
    "    def turns_left(self, path):\n",
    "        #0 is left 1 is right\n",
    "        direction_lst = []\n",
    "        for i in range(len(path)-1):\n",
    "            current = path[i]\n",
    "            nxt = path[i+1]\n",
    "            #Checks\n",
    "            if nxt == 0:\n",
    "                #We went left\n",
    "                direction_lst.append(0)\n",
    "            #Checks\n",
    "            elif nxt == current*self.degree + self.degree - 1:\n",
    "                #We went right\n",
    "                direction_lst.append(1)\n",
    "            elif current == 0 and current < nxt:\n",
    "                #We went left\n",
    "                direction_lst.append(0)\n",
    "            else:\n",
    "                direction_lst.append(0)\n",
    "\n",
    "        return direction_lst\n",
    "    \n",
    "    def answer(self, dates):\n",
    "        \"\"\"Calculates the path of index in full binary string\n",
    "\n",
    "        Parameters:\n",
    "        dates (tuple of string): Two dates in the format string 2000-12-19. \n",
    "\n",
    "        Returns:\n",
    "        float: The private range count\n",
    "        \"\"\"\n",
    "\n",
    "        if (len(dates) < 2):\n",
    "            date_obj_0 = datetime.strptime(dates[0],'%Y-%m-%d').date()\n",
    "            #print(date_obj_0)\n",
    "            #print(type(date_obj_0))\n",
    "            idx = self.idx_dict[date_obj_0]\n",
    "            \n",
    "            return self.tree_levels[len(self.tree_levels)-1][idx]\n",
    "  \n",
    "        else:\n",
    "            date_obj_0 = datetime.strptime(dates[0],'%Y-%m-%d').date()\n",
    "            date_obj_1 = datetime.strptime(dates[1],'%Y-%m-%d').date()\n",
    "\n",
    "\n",
    "            idx_0 = self.idx_dict[date_obj_0]\n",
    "            idx_1 = self.idx_dict[date_obj_1]\n",
    "\n",
    "            #print(idx_0)\n",
    "            #print(idx_1)\n",
    "            idx_left = idx_0-1\n",
    "            idx_right = idx_1+1\n",
    "\n",
    "            path_to_left = np.flip(np.array(self.get_index(idx_left,self.T)))\n",
    "            path_to_right = np.flip(np.array(self.get_index(idx_right,self.T)))\n",
    "\n",
    "            left_or_right_list_leftside = self.turns_left(path_to_left)\n",
    "            left_or_right_list_rightside = self.turns_right(path_to_right)\n",
    "            #Starting in 0\n",
    "\n",
    "            range_count = 0.0\n",
    "\n",
    "            if idx_0 == 0 and idx_1 == np.max(np.fromiter(self.idx_dict.values(), dtype = int)):\n",
    "                node = self.tree_levels[0]\n",
    "                range_count = node\n",
    "\n",
    "            elif idx_0 == 0:\n",
    "                print('We here')\n",
    "                level_offset = 0\n",
    "                \n",
    "                #print(f'level_offset = {level_offset}')\n",
    "                \n",
    "                \n",
    "                for i in range(len(left_or_right_list_rightside)):\n",
    "                    print(f'i = {i} and left_or_right_list_rightside = {left_or_right_list_rightside[i]}')\n",
    "\n",
    "                    if left_or_right_list_rightside[i] == 1:\n",
    "                        print('In here')\n",
    "                        \n",
    "                        group = self.get_group(path_to_right[i+level_offset], i+level_offset)\n",
    "                        idx_sss = np.where(group == path_to_right[i+level_offset])[0][0]\n",
    "                        print(f'group = {group} and idx_sss = {idx_sss}')\n",
    "\n",
    "                        count_nodes = self.tree_levels[i+level_offset][group[[idx_sss]]]\n",
    "                        print(group[[idx_sss]])\n",
    "                        print(f'count_nodes = {count_nodes}')\n",
    "                        \n",
    "                        for node in count_nodes:\n",
    "                            #print(node)\n",
    "                            range_count = range_count + node\n",
    "\n",
    "            elif idx_1 == np.max(np.fromiter(self.idx_dict.values(), dtype = int)):\n",
    "                #print('MAX')\n",
    "\n",
    "                level_offset = 1\n",
    "                #print(f'level_offset = {level_offset}')\n",
    "\n",
    "                for i in range(len(left_or_right_list_leftside)):\n",
    "                    if left_or_right_list_leftside[i] == 0:\n",
    "\n",
    "                        group = self.get_group(path_to_left[i+level_offset], i+level_offset)\n",
    "                        idx_sss = np.where(group == path_to_left[i+level_offset])[0][0]\n",
    "\n",
    "                        count_nodes = self.tree_levels[i+level_offset][group[idx_sss+1:]]\n",
    "                        for node in count_nodes:\n",
    "                            #print(node)\n",
    "                            range_count = range_count + node\n",
    "\n",
    "\n",
    "            else:\n",
    "                level_offset = 1\n",
    "                #print(f'level_offset = {level_offset}')\n",
    "                left_count = []\n",
    "                left_count_group = []\n",
    "\n",
    "                for i in range(len(left_or_right_list_rightside)):\n",
    "                    if left_or_right_list_rightside[i] == 1:\n",
    "                        group = self.get_group(path_to_right[i+level_offset], i+level_offset)\n",
    "                        idx_sss = np.where(group == path_to_right[i+level_offset])[0][0]\n",
    "\n",
    "                        left_count_group.append(group[:idx_sss]) \n",
    "\n",
    "                        count_nodes = self.tree_levels[i+level_offset][group[:idx_sss]]\n",
    "                        left_count.append(count_nodes)\n",
    "\n",
    "                    else:\n",
    "                        left_count_group.append(np.array([]))\n",
    "                        left_count.append(np.array([]))\n",
    "\n",
    "                #The search right side\n",
    "                right_count = []\n",
    "                right_count_group = []\n",
    "\n",
    "                for i in range(len(left_or_right_list_leftside)):\n",
    "                    if left_or_right_list_leftside[i] == 0:\n",
    "\n",
    "                        group = self.get_group(path_to_left[i+level_offset], i+level_offset)\n",
    "                        idx_sss = np.where(group == path_to_left[i+level_offset])[0][0]\n",
    "\n",
    "                        right_count_group.append(group[idx_sss+1:]) \n",
    "\n",
    "                        count_nodes = self.tree_levels[i+level_offset][group[idx_sss+1:]]\n",
    "                        right_count.append(count_nodes)\n",
    "\n",
    "                    else:\n",
    "                        right_count_group.append(np.array([]))\n",
    "                        right_count.append(np.array([]))\n",
    "\n",
    "                #print('Counting nodes')\n",
    "                #print(left_count)\n",
    "                #print(right_count)\n",
    "                for i in range(len(left_count_group)):\n",
    "                    #print(f'At level {level_offset + i}')\n",
    "                    \"\"\"\n",
    "                    print('Left size')\n",
    "                    print(left_count_group[i].size)\n",
    "                    print('right size')\n",
    "                    print(right_count_group[i].size)\n",
    "                    \"\"\"\n",
    "                    if left_count_group[i].size != 0 and right_count_group[i].size != 0:\n",
    "                        #print('Both not zero')\n",
    "                        group_left = self.get_group(left_count_group[i][0], i+ level_offset)\n",
    "                        group_right = self.get_group(right_count_group[i][0], i+ level_offset)\n",
    "\n",
    "                        if not (np.array_equal(group_left,group_right)):\n",
    "                            for node in left_count_group[i]:\n",
    "                                range_count = range_count + node\n",
    "                                #print(node)\n",
    "                            for node in right_count_group[i]:\n",
    "                                range_count = range_count +node\n",
    "                                #print(node)\n",
    "                        else:\n",
    "                            #print(left_count_group[i])\n",
    "                            #print(right_count_group[i])\n",
    "                            #print(np.intersect1d(left_count_group[i], right_count_group[i]))\n",
    "                            count_nodes = np.intersect1d(left_count_group[i], right_count_group[i])\n",
    "                            for node in count_nodes:\n",
    "                                range_count = range_count + node\n",
    "                                #print(node)\n",
    "\n",
    "                    if left_count_group[i].size != 0 and right_count_group[i].size == 0:\n",
    "                        #print('Left not zero')\n",
    "                        for node in left_count_group[i]:\n",
    "                            range_count = range_count + node\n",
    "                            #print(node)\n",
    "                    if right_count_group[i].size != 0 and left_count_group[i].size == 0:\n",
    "                        #print('Right not zero')\n",
    "                        for node in right_count_group[i]:\n",
    "                            #print(node) \n",
    "                            range_count = range_count + node\n",
    "\n",
    "                        #print(OLH_answer(count, epsilon, np.sum(OLH_count), D))\n",
    "                        #D = len(all_dates) \n",
    "        return range_count \n",
    "\n",
    "        \n",
    "    def real_answer(self, dates):\n",
    "        if len(dates) < 2:\n",
    "            date_obj_0 = datetime.strptime(dates[0],'%Y-%m-%d').date()\n",
    "            return self.all_counts[self.idx_dict[date_obj_0]]\n",
    "        else:\n",
    "            date_obj_0 = datetime.strptime(dates[0],'%Y-%m-%d').date()\n",
    "            date_obj_1 = datetime.strptime(dates[1],'%Y-%m-%d').date()\n",
    "            sum_ = np.sum(self.all_counts[self.idx_dict[date_obj_0]: self.idx_dict[date_obj_1]+1])  \n",
    "            return sum_\n",
    "        \n",
    "\n",
    "T = len(dates)\n",
    "epsilon = 0.7\n",
    "c_o = cen_hh(epsilon, all_dates, all_counts, 2)\n",
    "\n",
    "query_dates = ('2014-01-08','2014-01-09')\n",
    "print(c_o.answer(query_dates))\n",
    "print(c_o.real_answer(query_dates))\n",
    "#print(execRangeQuery(param_dic,query_dates)[0][0])\n",
    "\n",
    "print(c_o.answer(('2014-01-20',)))\n",
    "print(c_o.real_answer(('2014-01-20',)))\n",
    "\n",
    "print(c_o.answer(('2014-01-02','2014-01-05')))\n",
    "print(c_o.real_answer(('2014-01-02','2014-01-05')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (81,) (1794,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-285-b377a511f849>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mc_o\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcen_hh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_dates\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m81\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_counts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m81\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#print(c_o.laplaces)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#print(c_o.histogram)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlevel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mc_o\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_levels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-284-b5de38bd625c>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, epsilon, dates, counts, degree)\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlaplaces\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_laplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistogram\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_histogram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_levels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__process\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall_counts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minit_laplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-284-b5de38bd625c>\u001b[0m in \u001b[0;36m__process\u001b[1;34m(self, counts)\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[0mhh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlaplaces\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m             \u001b[0mlevel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlaplaces\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m             \u001b[0mhh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhh\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (81,) (1794,) "
     ]
    }
   ],
   "source": [
    "c_o = cen_hh(epsilon, all_dates[:81], all_counts[:81], 3)\n",
    "#print(c_o.laplaces)\n",
    "#print(c_o.histogram)\n",
    "\n",
    "for level in c_o.tree_levels:\n",
    "    print(level)\n",
    "\n",
    "query_dates = ('2014-01-02','2014-01-12')\n",
    "print(c_o.answer(query_dates))\n",
    "print(c_o.real_answer(query_dates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[239. 118. 129.   2. 293. 362. 288. 250.  76.  89.   1. 253. 364. 241.\n",
      "   0. 388.  80.   4. 315. 365. 266. 244.  51.  88.   5. 260. 353. 251.\n",
      " 288. 116. 176. 126.   0. 675. 269. 272.  87. 168.   6. 261. 239. 257.\n",
      " 251.  54.   0.   0. 471. 445. 328. 351.  78.  69.  20. 333. 390. 326.\n",
      " 286. 103. 128.  30. 290. 388. 362. 269.  76. 285.  33. 329.  81. 607.\n",
      " 296.  87. 109.  53. 308. 354. 326.   0. 378.  94.  56.]\n",
      "1847.0\n",
      "13287.0\n"
     ]
    }
   ],
   "source": [
    "print(all_counts[:81])\n",
    "print(np.sum(all_counts[:11]))\n",
    "print(np.sum(all_counts[:64]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(c_o.tree_levels[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query_dates = ('2014-01-08','2014-01-09')\n",
    "print(c_o.answer(query_dates))\n",
    "print(c_o.real_answer(query_dates))\n",
    "print(execRangeQuery(param_dic,query_dates)[0][0])\n",
    "\n",
    "print(c_o.answer(('2014-01-20',)))\n",
    "print(c_o.real_answer(('2014-01-20',)))\n",
    "\n",
    "print(c_o.answer(('2014-01-02','2014-01-05')))\n",
    "print(c_o.real_answer(('2014-01-02','2014-01-05')))\n",
    "\n",
    "\n",
    "\n",
    "for key, value in c_o.idx_dict.items():\n",
    "    print(key, ' : ', value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relative_error_percentage(x_approx, x_true):\n",
    "    # | (V - Vapprox) / V | x 100% \n",
    "    return np.abs((x_true-x_approx)/x_true)*100\n",
    "\n",
    "\n",
    "def relative_error(x_approx, x_true):\n",
    "    # | 1 - (Vapprox / V) | \n",
    "    return np.abs(1-(x_approx/x_true))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons = np.array([2,1.4,1.2,1,0.8,0.7,0.5,0.4,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_dicts = {}\n",
    "\n",
    "for e in epsilons:\n",
    "    print(e)\n",
    "    number_of_queries = 100\n",
    "    range_dates = ('2014-01-08','2014-01-09')\n",
    "    answears = np.zeros(number_of_queries)\n",
    "    corret_answear = execRangeQuery(param_dic,range_dates)[0][0]\n",
    "    for i in range(0,number_of_queries):\n",
    "        c_o = con_obs(epsilon, dates, counts)\n",
    "        answears[i] = c_o.answer(('2014-01-08','2014-01-09'))\n",
    "    error = np.abs(corret_answear-answears)\n",
    "    max_error = np.amax(error)\n",
    "    min_error = np.amin(error)\n",
    "    true_values = np.full(number_of_queries, corret_answear)\n",
    "    vfunc = np.vectorize(relative_error)\n",
    "    rel_erorrs = vfunc(answears, corret_answear)\n",
    "    mse = mean_squared_error(true_values, answears)\n",
    "    error_dicts[e] = {'mse': mse, 'max': max_error, 'min': min_error, 'rel': np.mean(rel_erorrs), 'abs': np.mean(error)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting all error values from dict\n",
    "n = len(error_dicts)\n",
    "mse_errors = np.zeros(n)\n",
    "min_errors = np.zeros(n)\n",
    "max_errors = np.zeros(n)\n",
    "rel_errors = np.zeros(n)\n",
    "abs_errors = np.zeros(n)\n",
    "\n",
    "for num, item in enumerate(error_dicts.items()):\n",
    "    mse_errors[num] = item[1]['mse']\n",
    "    min_errors[num] = item[1]['min']\n",
    "    max_errors[num] = item[1]['max']\n",
    "    rel_errors[num] = item[1]['rel']\n",
    "    abs_errors[num] = item[1]['abs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_stack = np.vstack((min_errors,mse_errors,max_errors,rel_errors,abs_errors)).flatten()\n",
    "min_labels = np.full(min_errors.size, 'min errors')\n",
    "mse_labels = np.full(mse_errors.size, 'mse errors')\n",
    "max_labels = np.full(max_errors.size, 'max errors')\n",
    "rel_labels = np.full(rel_errors.size, 'rel errors')\n",
    "abs_labels = np.full(rel_errors.size, 'abs errors')\n",
    "\n",
    "\n",
    "labels_stack = np.vstack((min_labels,mse_labels,max_labels,rel_labels,abs_labels)).flatten()\n",
    "epsilons_stack = np.vstack((epsilons,epsilons,epsilons,epsilons,epsilons)).flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn_df = pd.DataFrame({'epsilons':epsilons_stack, 'errors':error_stack,'labels':labels_stack})\n",
    "seaborn_df.to_csv('con_obs_seaborn_plotting_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.DataFrame({'epsilons':epsilons, 'min_errors':min_errors,'max_errors':min_errors,'mse_errors':mse_errors,'rel_errors':rel_errors,'abs_errors':abs_errors})\n",
    "all_data.to_csv('con_obs_plotting_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns_plot = sns.catplot(x=\"epsilons\", y=\"errors\", hue=\"labels\", data=seaborn_df)\n",
    "sns_plot.set(yscale=\"log\")\n",
    "sns_plot.savefig(\"con_AllErrors.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns_plot = sns.scatterplot(data=seaborn_df.loc[seaborn_df['labels'] == 'min errors'], x ='epsilons', y ='errors')\n",
    "plt.legend(labels=['min errors'])\n",
    "sns_plot.get_figure().savefig('con_min_error.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns_plot = sns.scatterplot(data=seaborn_df.loc[seaborn_df['labels'] == 'max errors'], x ='epsilons', y ='errors')\n",
    "plt.legend(labels=['max errors'])\n",
    "sns_plot.get_figure().savefig('con_max_error.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns_plot = sns.scatterplot(data=seaborn_df.loc[seaborn_df['labels'] == 'mse errors'], x ='epsilons', y ='errors')\n",
    "plt.legend(labels=['mse errors'])\n",
    "sns_plot.get_figure().savefig('con_mse_error.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns_plot = sns.scatterplot(data=seaborn_df.loc[seaborn_df['labels'] == 'rel errors'], x ='epsilons', y ='errors')\n",
    "plt.legend(labels=['rel errors'])\n",
    "sns_plot.get_figure().savefig('con_rel_error.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
